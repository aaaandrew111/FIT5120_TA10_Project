{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faaa9844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Import Flask modules\n",
    "from flask import Flask, request, render_template\n",
    "\n",
    "# 需要用到的库\n",
    "import pickle\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1decffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Flask and set the template folder to \"template\"\n",
    "app = Flask(__name__, template_folder = 'template')\n",
    "\n",
    "# 建立一个class类\n",
    "class Data_Process:\n",
    "    \n",
    "    # 初始化class\n",
    "    def __init__(self):\n",
    "        self.categories = ['Kitchens', 'Electronics', 'Sports', 'Cloths', 'Movies']\n",
    "        return\n",
    "    \n",
    "    # 加载模型，处理数据，进行预测流程，最终返回预测结果\n",
    "    def process(self, text, category='Kitchens'):\n",
    "        self.text = text\n",
    "        self.category = category\n",
    "        self.load_model()\n",
    "        self.transform_data()\n",
    "        self.make_prediction()\n",
    "        return self.fake_prob\n",
    "    \n",
    "    \n",
    "    # 加载对应模型和transformer\n",
    "    def load_model(self):\n",
    "        path = './models/' +  self.category + \".pkl\" \n",
    "        with open(path, 'rb') as file:  \n",
    "            model = pickle.load(file)\n",
    "        file.close()\n",
    "        \n",
    "        path = './transformers/' +  self.category + \".pickle\" \n",
    "        with open(path, 'rb') as file:  \n",
    "            transformer = pickle.load(file)\n",
    "        file.close()\n",
    "        \n",
    "        self.model = model\n",
    "        self.transformer = transformer\n",
    "        return\n",
    "    \n",
    "    # 对数据进行清洗转换\n",
    "    def transform_data(self):\n",
    "        sentence=str(self.text)\n",
    "    \n",
    "        # lower case\n",
    "        sentence = sentence.lower()\n",
    "\n",
    "        # remove special characters\n",
    "        sentence=sentence.replace('{html}',\"\") \n",
    "        cleanr = re.compile('<.*?>')\n",
    "        cleantext = re.sub(cleanr, '', sentence)\n",
    "        rem_url=re.sub(r'http\\S+', '',cleantext)\n",
    "        rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "\n",
    "        # tokenization\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        tokens = tokenizer.tokenize(rem_num)  \n",
    "        \n",
    "        # remove stopwords\n",
    "        filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
    "        #filtered_words = [w for w in tokens if len(w) > 2]\n",
    "        \n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        stemmer = PorterStemmer() \n",
    "        # stemming and lemmatization\n",
    "        stem_words=[stemmer.stem(w) for w in filtered_words]\n",
    "        #stem_words = filtered_words\n",
    "        lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
    "    \n",
    "        cleansed_sentence = \" \".join(lemma_words)\n",
    "        self.transformed_data = self.transformer.transform([cleansed_sentence])\n",
    "        return\n",
    "    \n",
    "    # 进行fake review 可能性预测\n",
    "    def make_prediction(self):\n",
    "        self.fake_prob = round(self.model.predict_proba(self.transformed_data)[0][1], 2)\n",
    "        #print(self.model.classes_)\n",
    "        return    \n",
    "\n",
    "\n",
    "#create our \"home\" route using the \"index.html\" page\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "\n",
    "#Set a post method to yield predictions on page\n",
    "@app.route('/', methods = ['POST'])\n",
    "def predict():\n",
    "    \n",
    "    #obtain all form values and place them in an array, convert into integers\n",
    "    # int_features = [int(x) for x in request.form.values()]\n",
    "    to_predict_list = request.form.to_dict()\n",
    "    to_predict_list = list(to_predict_list.values())\n",
    "    to_predict_list = list(map(str, to_predict_list))\n",
    "    \n",
    "    \n",
    "    category = to_predict_list[0]\n",
    "    user_text = to_predict_list[1]\n",
    "    d = Data_Process()\n",
    "    output = d.process(user_text, category)\n",
    "    \n",
    "    \n",
    "    #If the output is negative, the values entered are unreasonable to the context of the application\n",
    "    #If the output is greater than 0, return prediction\n",
    "    if output < 0:\n",
    "        return render_template('index.html', prediction_text = \"Predicted probability is negative, values entered not reasonable\")\n",
    "    elif output >= 0:\n",
    "        return render_template('index.html', prediction_text = '{:.0%}'.format(output))   \n",
    "\n",
    "    \n",
    "#Run app\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35a2d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8865de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c340c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3fdf23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
